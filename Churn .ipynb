{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE  # imblearn library can be installed in Visual Studio by going into Python Environment -> Install new package -> imblearn package\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"ChurnPrediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information of given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This shows that their are total 1470 entries with zero null values.Different coloumn have datatype. So we have to pre-process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe function will give the max,min,sd of all the attributes also different Q ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique values in specific coloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['PastEmployee'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['BusinessTravel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['EducationField'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['JobRole'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['MaritalStatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['OverTime'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Categorical features into Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a converter function that can convert yes and no values in coloumns into 1 and 0 respectively.\n",
    "def converter(column):\n",
    "    if column == 'Yes':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['PastEmployee'] = dataset['PastEmployee'].apply(converter)\n",
    "dataset['OverTime'] = dataset['OverTime'].apply(converter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']\n",
    "final_data = pd.get_dummies(dataset, columns = categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about dataset after following changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This shows that there is no categorical data in the above dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataset into label and feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop('PastEmployee', axis = 1) # Features set which will store only the features coloumns and drop all the unwanted coloumn, also we need to drop label data or target coloumn from the given dataset\n",
    "Y = final_data['PastEmployee'] # Labels set which holds the target coloumn and their should always be only one coloumn in label set.\n",
    "print(type(X))\n",
    "print(type(Y))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.shape shows that their are 1470 rows and 46 coloumns whereas in Y their are one coloumn with 1470 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing numerical features so that each feature has mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split( X_scaled, Y, test_size = 0.3, random_state = 100)\n",
    "#test size = 0.3 means that 30% od data will be treated as test data and remaining 70% as training data\n",
    "#random_state= 100 is set so that we ever we run the code we will get same random number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out off 1470 -> 1029 is taken as training set and 441 as test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Oversampling to balance the dataset; SMOTE stands for Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of observations in each class before oversampling (training data): \\n\", pd.Series(Y_train).value_counts())\n",
    "\n",
    "smote = SMOTE(random_state = 101)\n",
    "X_train,Y_train = smote.fit_sample(X_train,Y_train)\n",
    "\n",
    "print(\"Number of observations in each class after oversampling (training data): \\n\", pd.Series(Y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Classification Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "dtree.fit(X_train, Y_train)\n",
    "featimp = pd.Series(dtree.feature_importances_, index=list(X)).sort_values(ascending=False)\n",
    "print(featimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evatuation is done for 5 depth. 0 value is because they are not taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Decision Tree Model\n",
    "Y_pred = dtree.predict(X_test)\n",
    "print(\"Prediction Accuracy: \", metrics.accuracy_score(Y_test, Y_pred)) # Not a good idea coz imbalanced test set\n",
    "conf_mat = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat,annot=True)\n",
    "plt.title(\"Confusion_matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Actual class\")\n",
    "plt.show()\n",
    "print('Confusion matrix: \\n', conf_mat)\n",
    "print('TP: ', conf_mat[1,1])\n",
    "print('TN: ', conf_mat[0,0])\n",
    "print('FP: ', conf_mat[0,1])\n",
    "print('FN: ', conf_mat[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the tree size parameter 'max_depth' and implementing cross-validation using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='entropy', max_features='auto', random_state=1)\n",
    "grid_param = {'n_estimators': [200, 250, 300, 350, 400, 450]}\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=rfc, param_grid=grid_param, scoring='recall', cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "In the above GridSearchCV(), scoring parameter should be set as follows:\n",
    "scoring = 'accuracy' when you want to maximize prediction accuracy\n",
    "scoring = 'recall' when you want to minimize false negatives\n",
    "scoring = 'precision' when you want to minimize false positives\n",
    "scoring = 'f1' when you want to balance false positives and false negatives (place equal emphasis on minimizing both)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr.fit(X_train, Y_train)\n",
    "\n",
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)\n",
    "\n",
    "best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building random forest using the tuned parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=400, criterion='entropy', max_features='auto', random_state=1)\n",
    "rfc.fit(X_train,Y_train)\n",
    "featimp = pd.Series(rfc.feature_importances_, index=list(X)).sort_values(ascending=False)\n",
    "print(featimp)\n",
    "\n",
    "Y_pred = rfc.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat,annot=True)\n",
    "plt.title(\"Confusion_matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Actual class\")\n",
    "plt.show()\n",
    "print('Confusion matrix: \\n', conf_mat)\n",
    "print('TP: ', conf_mat[1,1])\n",
    "print('TN: ', conf_mat[0,0])\n",
    "print('FP: ', conf_mat[0,1])\n",
    "print('FN: ', conf_mat[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features with higher sifnificance and redefining feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data[['OverTime', 'Age', 'JobSatisfaction', 'StockOptionLevel', 'MonthlyIncome']]\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split( X_scaled, Y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "smote = SMOTE(random_state = 101)\n",
    "X_train,Y_train = smote.fit_sample(X_train,Y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=400, criterion='entropy', max_features='auto', random_state=1)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = rfc.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat,annot=True)\n",
    "plt.title(\"Confusion_matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Actual class\")\n",
    "plt.show()\n",
    "print('Confusion matrix: \\n', conf_mat)\n",
    "print('TP: ', conf_mat[1,1])\n",
    "print('TN: ', conf_mat[0,0])\n",
    "print('FP: ', conf_mat[0,1])\n",
    "print('FN: ', conf_mat[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
